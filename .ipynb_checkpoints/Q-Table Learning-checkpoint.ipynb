{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n, env.action_space.n "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Implement Q-Table Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Learning Parameters\n",
    "LearningRate = 0.8\n",
    "y = 0.98\n",
    "NumberOfEpisodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create lists to contain total rewards and steps per episode \n",
    "RList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(NumberOfEpisodes):\n",
    "    # Reset\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    # Q-Table Learning Algorithm\n",
    "    while j < 99:\n",
    "        j += 1\n",
    "        \n",
    "        # Choose an action by greedily (with noise) picking from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1, env.action_space.n)*(1./(i+1)))\n",
    "        \n",
    "        s1, r, d, _ = env.step(a)\n",
    "        \n",
    "        Q[s,a] = Q[s,a] + LearningRate * (r + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        \n",
    "        if d == True:\n",
    "            break\n",
    "            \n",
    "        RList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Score over time: \" + str(sum(RList)/NumberOfEpisodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.73785610e-01, 0.00000000e+00, 1.56280889e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.78680494e-04, 2.34285440e-01],\n",
       "       [3.91794743e-03, 4.54871287e-03, 7.74098202e-04, 9.79056625e-02],\n",
       "       [2.90151935e-03, 0.00000000e+00, 2.66970061e-03, 6.77784993e-02],\n",
       "       [6.48905657e-01, 3.39533253e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.38773744e-02, 1.47533339e-05, 1.60739274e-04, 2.62702111e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.90167054e-03, 0.00000000e+00, 0.00000000e+00, 6.88299011e-01],\n",
       "       [0.00000000e+00, 5.62069039e-01, 3.85391595e-03, 2.45849552e-03],\n",
       "       [8.02503968e-01, 2.41088982e-04, 3.86028732e-04, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 6.13942400e-03, 8.72829787e-01, 4.33722034e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.93651706e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Final Q-Table values\"\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
